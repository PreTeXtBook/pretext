<?xml version="1.0" encoding="UTF-8"?>

<!--   This file is part of the documentation of PreTeXt      -->
<!--                                                          -->
<!--      PreTeXt Author's Guide                              -->
<!--                                                          -->
<!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
<!-- See the file COPYING for copying conditions.             -->

<chapter xml:id="xsltproc">
  <title>Processing with <c>xsltproc</c></title>
  <introduction>
    <p>
      The executable program <c>xsltproc</c>
      <idx>
        <c>xsltproc</c>
      </idx> implements Version 1.0 of the <term>eXtensible Stylesheet Language (XSL)</term>
      <idx>XSL</idx>.  This is a declarative language that walks the hierarchical tree of an XML source file, and for each element describes some output to produce before, and after, recursively processing the contained elements.  (That is a simplified description.)
    </p>

    <p>
      <c>xsltproc</c> is typically installed by default on Linux systems and as part of Mac OS.  See the <pretext /> website for details for Windows systems.  The most basic operation is to provide <c>xsltproc</c> with an XSL stylesheet from the <pretext /> distribution and an XML document of your creation that is valid <pretext />.  This is done at the command-line, inside of a terminal or shell.  Describing command-line operations, along with file and directory management, is beyond the scope of this guide, so consult another resource if this is unfamiliar.  So here is a hypothetical simple example:
    </p>

    <console>
      <input prompt="rob@lava:~/pretext$ ">xsltproc xsl/pretext-html.xsl ~/books/aota/animals.xml</input>
    </console>

    <p>
      By default, <c>xsltproc</c> writes output to <c>stdout</c> (the screen), which you could redirect to a file, or you could use the <c>-o</c> switch to send the output to a named file.  However, <pretext />
      automatically writes to a file whose name is derived from the <attr>xml:id</attr> attribute of the top-level <tag>book</tag> or <tag>article</tag> tag.  If no such attribute is given the filename will be derived from <c>book-1</c> or <c>article-1</c>.  All output is produced in whatever the current default directory is, so you will likely want to set this beforehand.
    </p>

    <p>
      The <c>xsl</c> subdirectory of the <pretext />
      distribution contains a variety of XSL stylesheets<idx>XSL stylesheet</idx>, which I will also refer to as <term>converters</term>
      <idx>
      <h>converter</h>
      <see>XSL stylesheet</see>
      </idx> or <term>conversions</term>
      <idx>
      <h>conversion</h>
      <see>XSL stylesheet</see>
      </idx>.
      The ones that you will use as an author all have filenames of the form <c>xsl/pretext-XXX.xsl</c>, where <c>XXX</c> is some indication of the output produced.  Conversions to <latex />or HTML output are the two most mature converters.
    </p>

    <p>
      Note that authors are not responsible for creating XSL stylesheets.  Stock conversions are part of the <pretext />
      distribution, and anybody is welcome to assume a source document is valid <pretext />
      and create new conversions to process it to existing, or as yet unimagined, formats.
    </p>

  </introduction>
  <section xml:id="xsltproc-setup">
    <title>Setup</title>

    <p>There are two components to processing your document, the <pretext />
    stylesheets and the <c>xsltproc</c> program.  We work at the <term>command-line</term>
    <idx>command-line</idx> inside of a <term>terminal</term>
    <idx>terminal</idx> or <term>console</term>
    <idx>console</idx>.  If you do not know what this is, it will seem very primitive at first.  Sometimes the old ways are the best ways.  This will be called a <q>Command Prompt</q> in Windows or a <q>Terminal</q> on a Mac.  In Linux it may be known as a <q>console</q> or a <q>shell</q>.  A tutorial, which is Linux-specific, can be found at <url href="http://ryanstutorials.net/linuxtutorial/" visual="ryanstutorials.net/linuxtutorial/">Ryan's Tutorials</url> and certainly others exist.</p>
    <p>The operating system on a Mac is built on Unix, which is very similar to Linux, so most of the directions here will be little changed between the two.  Procedures can be very different in Windows (<xref ref="windows-install-notes" />
    ,<xref ref="windows-subsystem-linux" />
    ).  One alternative is <url href="https://cocalc.com/" visual="cocalc.com">CoCalc</url>
    which provides a full Linux computer for free in your web browser, so that may be an excellent place for initial experiments.</p>

    <paragraphs>
    <title>Step 1: <pretext />
    </title>

    <p>You need to obtain the <pretext />
    stylesheets, which are the main part of <pretext />
    .  Since you are reading this, it may be possible that you have this already.  You can use <c>git</c> to <term>clone</term> the <pretext />
    from the GitHub repository, and then be sure to checkout the <c>dev</c> branch to have the latest version.  This is the best way to go, and you should only download the repository as a zip file once for an initial experiment, and then switch to using a clone instead.</p>

    <p>Once you have a clone of the repository, you can issue <c>git pull</c>, and git will update your local copy with any recent changes.  You should do this <em>regularly</em>
    <mdash />
    meaning on the order of <em>daily</em>.  See the <xref ref="faq-pull-regularly" text="custom">FAQ entry</xref> for more about why we <em>expect</em> you to do this.</p>

    <p>See the <url href="https://pretextbook.org/" visual="pretextbook.org">
    <pretext/>
    site</url> for details and commands for this step, right on the main page.</p>
    </paragraphs>

    <paragraphs>
    <title>Step 2: <c>xsltproc</c>
    </title>

    <p>This is the command-line program which takes your document and a <pretext />
    stylesheet to together produce output.  On Linux or a Mac you probably already have it installed as part of system software.  On Windows it is not so simple.</p>

    <p>In either case see the website for details abut verifying you have this, or how to install it.</p>
    </paragraphs>

  </section>

  <section xml:id="xsltproc-processing">
    <title>Processing</title>

    <p>At a command prompt in your terminal or console adjust the path names for the two files and execute:<cd>
    <cline>xsltproc /path/to/pretext/xsl/pretext-html.xsl /path/to/quickstart.xml</cline>
    </cd>In the current working directory you should now find the file <c>article-1.html</c> which you can view in a web browser.  (You will want an internet connection since various parts of the page come from the network.  Someday we will create output for the offline situation.)  It will look very plain, but you should be able to read the sentence.</p>

    <p>Now, try the following, again with adjusted paths, and all on one line:
      <cd>
      <cline>xsltproc -o quick.tex /path/to/pretext/xsl/pretext-latex.xsl</cline>
      <cline>/path/to/quickstart.xml</cline>
      </cd>
    </p>

    <p>In the current working directory you should now find the file <c>quick.tex</c> which you can process with <c>pdflatex</c> or <c>xelatex</c> at the command line as below.  If you do not have <latex />
    installed on your system, you could process this file within a variety of online services, and CoCalc would be an obvious choice.<cd>
    <cline>pdflatex quick.tex</cline>
    </cd>In the current working directory you should now find the file <c>quick.pdf</c> which you can view or print with standard PDF viewing software.  You could even send it to a print-on-demand service to get nice hardback books, though I suspect sales will not be great.</p>

    <p> Note that if your project includes multiple files you will need to pass the <c>-xinclude</c> flag to <c>xsltproc</c>, though this is not needed for this simple example.
            An example of this is the command
    <cd>
    <cline>xsltproc -xinclude /path/to/pretext/xsl/pretext-html.xsl /path/to/index.xml</cline>
    </cd>
    For more on this see <xref ref="topic-xinclude"/>
    and <xref ref="processing-modular"/>.
    </p>

    <p>That's it.  You now know all the basics of authoring with <pretext />
    , since you have produced two radically different output formats with identical content from the exact same structured input, via two different command lines.  Everything you need to author a complete article or textbook, and produce it in many different formats, is just an extension or variation on what you just did.  Let us look at a few simple extensions right away before being more methodical.</p>
  </section>

  <section>
    <title>Modular Source Files</title>
    <p>
      If you use the <tag>xi:include</tag> mechanism for modular source files, you must process your source slightly differently.
    </p>

    <p>Add the switch <c>-xinclude</c> to your invocation of <c>xsltproc</c>, just after <c>xsltproc</c>, but before the filenames for the stylesheet and the top-level source file.  Note that for some versions of <c>xsltproc</c> it might be necessary to use two dashes for the switch, <c>--xinclude</c>.
                So now a typical invocation (using one dash) might look like
    <cd>
    <cline>xsltproc -xinclude xsl/pretext-html.xsl ~/books/aota/animals.xml</cline>
    </cd>
    </p>
    <p>It is easy to forget the <c>-xinclude</c> switch.  Empty output, or cryptic error messages, are your first clue to this simple, but common, mistake.</p>
    </section>

    <section xml:id="xsltproc-string-parameters">
    <title>String Parameters</title>
    <p>
                    To pass string parameters to <c>xsltproc</c>, use a command like the following (possibly with <c>--xinclude</c>).
    </p>

    <console>
    <input>xsltproc -o animals.tex --stringparam latex.font.size "20pt"</input>
    <input>  /path/to/xsl/pretext-latex.xsl ~/books/aota/animals.xml</input>
    </console>

    <p>
                    You can use as many <c>stringparam</c> as you like on the command-line (or in your scripts).  The quotation marks are not strictly needed in this example, but if the value of the parameter has spaces, slashes, etc., then you need to quote-protect the string from the command-line processor, and either single or double quotes will work (and protect the other kind).
    </p>
    </section>
    <section>
    <title>Extra XSL Stylesheets</title>
    <p>
                    If you want to use a custom <init>XSL</init> stylesheet, as described in <xref ref="publisher-extra-stylesheet"/>
    , it is a simple matter of using that custom as the <init>XSL</init> file fed to <c>xsltproc</c>.  That is, enter something like the following.
    </p>

    <console>
    <input>xsltproc -xinclude -o animals.tex ./xsl/custom-latex.xsl ~/books/aota/animals.xml</input>
    </console>

    <p>
                    Note that using this method, it is necessary to import the stock <init>XSL</init> using the <attr>href</attr> instead of <attr>pretext-href</attr>, as in <tage>xsl:import href="path/to/pretext/xsl/pretext-latex.xsl"</tage>.  You need to specify the full path to the <c>pretext/xsl</c> directory, or else put your custom <init>XSL</init> in the <c>pretext/user</c> directory and use a relative path (<c>../xsl/pretext-latex.xsl</c>).
    </p>
    </section>
    <section>
        <title>Publication File</title>

        <p>To employ a publication file using <c>xsltproc</c> you use a string parameter (<xref ref="publisher-string-parameters"/>) named <c>publisher</c>.  This should have a path that is relative to the main file for the document.  For example, assuming <c>pod.xml</c> and <c>fauna.xml</c> are in the same directory<cd>
            <cline>xsltproc -stringparam publisher pod.xml pretext-html.xsl aota.xml</cline>
        </cd>This file should reduce the many other string parameters in use, and reduce the need for extra <init>XSL</init> files (<xref ref="publisher-extra-stylesheet"/>).</p>
    </section>
    <section>
    <title>Images Described in Source</title>
    <p>
                    As we discussed in <xref ref="processing-images-pretext"/>
    , there are many advantages to describing images directly in the source of your <pretext />
    document.  However, these must be processed with various <q>helper</q> programs such as <c>asy</c>,<c>pdflatex</c>, and <c>sage</c>.
    </p>

    <p>
                    The issue with this is that XSL is not a general purpose programming language, and so in particular, cannot call the <q>helper</q> programs.  The general strategy is to use XSL to identify and isolate the parts of a document that lie in the elements designed for graphics languages.  A Python script, the <c>pretext</c> script, employs these XSL stylesheets and then feeds each image file to the appropriate helper program.
    </p>

    <p>
                    This script has a variety of options, so we document it fully in <xref ref="pretext-script" />
    .
    </p>
    </section>
    <section xml:id="xsltproc-author-tools">
    <title>Author Tools</title>
    <p>
                    The <c>authors-report.xsl</c> stylesheet, found in the <c>xsl/utilities</c> directory, will report all of the provisional cross-references and all of the properly prefixed todo-comments. The report is organized by all of the divisions in use in your project.  It is meant to be simple in appearance, just text.
    </p>

    <p>
                    Apply this stylesheet just like you would any other:
    </p>

    <console>
    <input>xsltproc -xinclude path/to/pretext/xsl/utilities/authors-report.xsl path/to/main.ptx</input>
    </console>
    </section>
    <section xml:id="xsltproc-updating-source">
    <title>Keeping Your Source Up-to-Date</title>
    <p>This section describes a tool you can use to automate the process of adjusting your source when there are deprecations.  Generally, there is an <init>XSL</init> stylesheet which will convert your <init>XML</init> source to another <init>XML</init> source file, fixing many of the deprecations automatically.  However, it is the nature of <init>XML</init> processing that your source file will undergo some cosmetic changes.  For example, the order of attributes is never relevant, so an <init>XML</init>-to-<init>XML</init> conversion is free to re-order the attributes of an element, perhaps different from how you like to author them.</p>

    <p>So you have two choices:<ul>
    <li>Process your source with any of the provided conversions and edit by hand until the warnings all disappear.</li>
    <li>Run the deprecation-fixing conversion and accept the changes in <init>XML</init> formatting. (Read on for more specifics about these changes.)</li>
    </ul>
    </p>

    <p>You perform this conversion using <c>xsl/utilities/fix-deprecations.xsl</c> on an <init>XML</init> source file in the usual way.  By default, output appears on the console, so you will want to specify an output file, for example with the <c>-o</c> flag of <c>xsltproc</c>.  You will discover a safety measure that requires you to also use a parameter, which you can pass in to <c>xsltproc</c> with the <c>-stringparam</c> command-line argument.</p>

    <p>One choice of the parameter will result in just <q>copying</q> your source file and making all the cosmetic source format changes (we refer to this here as <term>normalization</term>
    <idx>normalization</idx>).  This might be a useful thing to do first, all by itself, either as a first step, or an exploratory experiment.  The other value of the parameter will actually make changes, and report some information about progress.</p>

    <p>Here are some notes:<ol>
    <li>
    <p>Be sure to experiment on copies of your source in a scratch directory.  Send your output to another directory.  When finished, use a <c>diff</c> tool to inspect the actual changes made.  You can record your eventual changes using revision-control. (See <pubtitle>
    <url href="https://pretextbook.org/gfa/html/" visual="pretextbook.org/gfa/html/">Git for Authors</url>
    </pubtitle>.)
    </p>
    </li>
    <li>
    <p>Do not enable <c>xinclude</c> processing or else your several files will all be merged into one as output and any modularity of your source will be lost.</p>
    </li>
    <li>
    <p>Every single bit of indentation and whitespace in your source will be preserved, except perhaps for some blank lines near the top of your source files, and limited exceptions noted below.</p>
    </li>
    <li>
    <p>Attributes will likely be re-ordered, with normalized spacing between them.</p>
    </li>
    <li>
    <p>Empty elements will have any spaces removed from the end of the tag.</p>
    </li>
    <li>
    <p>Elements with no content may be written with a single empty tag.</p>
    </li>
    <li xml:id="deprecation-fixer-cdata">
    <p>
    <abbr>CDATA</abbr> sections will be converted to text acceptable to the <init>XML</init> parser.  In other words, the <abbr>CDATA</abbr> wrapper will be removed and dangerous characters (&amp;, &lt;, &gt;) will be replaced by equivalent entities (such as <c>&amp;amp;</c>).  If you have many matrices expressed in <latex />
            and wrapped in a <abbr>CDATA</abbr>, this might be a big change.  See <xref ref="topic-exceptional-characters"/>
            for background.</p>
    </li>
    <li>
    <p>The output files will be labeled as having <c>UTF-8</c> encoding.</p>
    </li>
    <li>
    <p>It could be necessary to run this conversion more than once if deprecations build on one another.  In other words, we do not update specific conversions, but rely on regular use to keep source up-to-date.</p>
    </li>
    <li>
    <p>It should be safe to run this conversion repeatedly, even after new deprecations are added.  In fact, it is encouraged.</p>
    </li>
    <li>
    <p>The <pretext />
            source file <c>examples/sample-errors-and-warnings.xml</c> is intentionally full of lots of bad stuff.  You can experiment with it, should you want to see interesting things happen.  We have already performed the normalization step, so you can concentrate on substantive changes.</p>
    </li>
    </ol>
    </p>

    <p>To process a directory with multiple source files, I would proceed as follows.  First make three temporary directories, <c>/tmp/original</c>,<c>/tmp/normal</c>,<c>/tmp/clean</c>, and copy my source files into <c>/tmp/original</c>.  Then, using a BASH shell, and inputting the command all on one long line.</p>

    <console>
    <input prompt="rob@lava:/tmp/original$ ">for f in *.xml; do xsltproc -o ../normal/$f -stringparam fix normalize</input>
    <input>  /home/rob/pretext/xsl/utilities/fix-deprecations.xsl $f; done</input>
    </console>

    <p>This will loop over every <init>XML</init> file in the current working directory, <c>/tmp/original</c>, running the normalization conversion on each file, with the output files using the same filename, but now being placed in the <c>/tmp/normal</c> directory.  If you change to the <c>/tmp</c> directory, then you can compare the results.  I like to use the <c>diff</c> utility provided by <c>git</c>.
    </p>

    <console>
    <input prompt="rob@lava:/tmp$ ">git diff original normal</input>
    </console>

    <p>Or, try this for a view that might be more informative.</p>

    <console>
    <input prompt="rob@lava:/tmp$ ">git diff --word-diff original normal</input>
    </console>

    <p>You may only do the above once, on your first use of this conversion stylesheet.  You will see how your style of authoring <init>XML</init> will undergo some minor changes.  We can repeat the above to actual make the changes necessary due to <pretext />
            deprecations.  Make <c>/tmp/normal</c> the working directory.</p>

    <console>
    <input prompt="rob@lava:/tmp/normal$ ">for f in *.xml; do xsltproc -o ../clean/$f -stringparam fix all</input>
    <input>  /home/rob/pretext/xsl/utilities/fix-deprecations.xsl $f; done</input>
    </console>

    <p>And as above, you can now compare the <c>normal</c> and <c>clean</c> directories to see actual changes.  If you are satisfied with the changes, you can copy the files in the <c>clean</c> directory back onto your source files.  If you are using revision-control (you are, aren't you?) then you can make a commit that holds these changes. (See <pubtitle>
    <url href="https://pretextbook.org/gfa/html/" visual="pretextbook.org/gfa/html/">Git for Authors</url>
    </pubtitle>.) Or maybe even make two commits, one from the normalization step, and a second with the substantive changes.</p>
    </section>

    <section xml:id="processing-file-management">
      <title>File Management</title>

      <p>
        <pretext />, at its core, is the formal specification of the XML vocabulary, as expressed in the DTD (<xref ref="processing-dtd" />).  We have provided converters to process source files into useful output.  However, we have not yet built a point-and-click application for the production of a book.  So you need to take some responsibility in a large project for managing your files, both input and output.  We have tried to provide flexible tools to make an author's job easier. The following is advice and practices we have successfully employed in several book projects.</p>

      <paragraphs>
        <title>Source</title>

        <p>I am fond of describing my own books with an initialism formed from the title.  So <pubtitle>A First Course in Linear Algebra</pubtitle> becomes <acro>FCLA</acro>, and in file and directory names becomes <c>fcla</c>.  So I have a top-level directory <c>books</c> and then <c>books/fcla</c>, but this directory is not the book itself, this is all the extra stuff that goes along with writing a book, much of it in <c>books/fcla/local</c>.  The actual book, the part everybody sees with an open license, lives in <c>books/fcla/fcla</c>.  This subdirectory has files like <c>COPYING</c>, which is a free software standard for license information, and <c>README.md</c> which is a file in the simplistic Markdown format that is picked up automatically by GitHub and displayed nicely at the book's repository's main page.  Subdirectories include <c>src</c> for the actual XML files, <c>xsl</c> for any customizing XSL (<xref ref="publisher-extra-stylesheet" />), and <c>script</c> for shell scripts used to process the book (see below).</p>

      <p>I do not use any additional directory structure below <c>src</c> to manage modular files for a book, since the XML and the <c>--xinclude</c> mechanism manage that just fine.  I see little benefit to extra subdirectories for organization and some resulting inconvenience.  I do typically have a single subdirectory <c>src/images</c> for raster images and other graphics files.</p>

      <p>I believe it is critically important to put your project under revision control, and if licensed openly, in a public GitHub repository.  So the <c>books/fcla/fcla</c> directory and all of its contents and subdirectories is tracked as a <c>git</c> repository and hosted on GitHub.  Because this directory is <em>source</em> I try very hard to <em>never</em> have any temporary files in these directories since I do not want to accidentally incorporate them into the <c>git</c> repository.  As a general rule-of-thumb, only original material goes in this directory and anything that can be re-created belongs outside.</p>

      <p>A tutorial on <c>git</c> would be way outside the scope of this guide, but Beezer and Farmer <em>have</em> written <pubtitle>Git For Authors</pubtitle>, so perhaps look for that.</p>
    </paragraphs>

    <paragraphs>
      <title>Image Files</title>

      <p>Some images are raster images (<eg /> photographs) that are not easily changed, and perhaps unlikely to be changed.  Other images will come from source-level languages via the <c>pretext</c> script.  For your convenience, this script has a command-line option that allows you to direct output (graphics files) to a directory of your choice.</p>

      <p>In the early stages of writing a book, I put image files<idx>image</idx> produced from source code in a directory outside of what is tracked by <c>git</c>. It is only when a project is very mature that I begin to include completed graphics files into the <c>src/images</c> directory for tracking by <c>git</c>.
    </p>
  </paragraphs>

  <paragraphs>
    <title>Build Scripts</title>

    <p>When you have a mature book project, the various files, processing options, and a desire for multiple outputs can all get a bit confusing.  Writing simple scripts<idx>script</idx> is a good idea and the investment of time doing this early in a project will pay off through the course of further writing and editing.  The particular setup you employ is less important.</p>

    <p>I have fallen into the habit of using the <c>make</c> program.  It allows me to define common variables upfront (such as paths to the <pretext /> distribution and the main directory for the project it applies to).  Then I can easily make <q>targets</q> for different outputs.  So, for example I typically go <c>make pdf</c> or <c>make html</c> to produce output, and have simple companion targets so that I can go <c>make viewpdf</c> or <c>make viewhtml</c>.  Other targets do things like checking my source against the DTD (<xref ref="processing-dtd" />).  I have split out the variable definitions in a way that a collaborator can join the project and simply edit the file of definitions just once to reflect their setup, and still participate in future upgrades to the script by pulling from GitHub and not overwrite their local information.</p>

    <p>My use of <c>make</c> is a bit of an abuse, since it is really designed for large software projects, with the aim of reducing duplicative compilations and that is not at all the purpose.  You could likely have exactly the same effect with a shell script and a case (or switch) statement.</p>

    <p>My general strategy is to assemble all the necessary files into a temporary directory (under <c>/tmp</c> in Linux) by copying them out of their permanent home, copy customizing XSL into the right place (typically <c>pretext/user</c>), run the <c>pretext</c> script as necessary and direct the results to the right place, and finally copy results out of the temporary directory if they are meant to be permanent.  Interesting, an exception to staging all these files is the source of the book itself which is only read for each conversion and then not needed for the output.  So you can just point directly to a top-level file and the <c>xinclude</c> mechanism locates any other necessary source files.</p>

    <p>A good example of this general strategy is the use and placement of image files for HTML output.  It is your responsibility to place images into the location your resulting HTML files expect to locate them.  By default, this is a subdirectory of the directory holding the HTML files, named <c>images</c>.  You will want to copy images, such as photographs, out of your main source directory (<c>src/images</c>?). But you may be actively modifying source code for diagrams, and you want to re-run the <c>pretext</c> script for each run, and make sure the output of the script is directed to the correct subdirectory for the HTML output.  Running the <c>pretext</c> script frequently can get tiresome, so maybe you have a makefile target <c>make diagrams</c> that updates a permanent directory, outside of your tracked files in the repository, and you copy those files into the correct subdirectory for the output.  That way, you can update images only when you are actively editing them, or when you are producing a draft that you want to be as up-to-date as possible.  As a project matures, you can add images into the directory tracked by <c>git</c> so they are available to others without getting involved with the <c>pretext</c> script.</p>

    <p>We did not say it would be easy, but we feel much of this sort of project management is outside the scope of the <pretext />
    project itself, while in its initial stages, and existing tools to manage the complexity are available and documented.  (We <em>have</em> been encouraged to create sample scripts, which we may do.)  Just remember the strategy: stage necessary components in a temporary directory, build output in that directory, copy out desired semi-permanent results, and limit additions to the source directory to that which is original, or mature and time-consuming to reproduce.</p>
  </paragraphs>
  </section>
  <section xml:id="xsltproc-doctest-sage">
    <title>Doctesting Sage Code</title>

    <p>Adding computer code to your textbook is a tricky proposition.  You can propose that it is merely an illustration, and not meant to have all the necessary details, or you can make it exact, correct and executable, and then risk inevitable changes to render your code obsolete.  At least you have the option of editing and reposting online versions quickly and easily.</p>

    <p>One of our main motivations for this project was mixing in code from the powerful, open source, mathematical software project, Sage (<xref ref="overview-sage" />).  When you add example Sage code to illustrate mathematical ideas, you are then encouraged to also include expected output in the <tag>output</tag> element.  Here comes one of the powerful advantages of XML source and XSL processing.</p>

    <p>The <c>pretext/xsl/pretext-sage-doctest.xsl</c> stylesheet, used in the usual way, will create one, or several file(s), in <em>exactly</em> the format Sage expects for automated testing.  So all your words are gone, and all your Sage input and output is packaged so Sage can run all the <tag>input</tag> and compare the results to the expected <tag>output</tag>.  See <xref ref="common-chunking-options"/> for details on obtaining more than one file.</p>

    <p>We have many years' experience testing hundreds of non-trivial Sage examples from textbooks, for linear algebra and abstract algebra.  Roughly every six months, we discover ten to twenty examples that fail.  Frequently the failures are trivial (usually output gets re-ordered), but some are significant changes in behavior that leads us to re-word surrounding guidance in the text, and in a few cases the failures have exposed bugs introduced into Sage.  It has been relatively easy to do this maintenance on a regular basis, and if it had not been done, the accumulated errors would be enough to greatly degrade confidence in the accuracy of the examples.</p>

    <p>Exact details for this process can be found in <xref ref="topic-doctest-sage" />.  Note that Sage is really just a huge Python library, so it might be possible to test pure Python code with this facility, but we have not tested this at all.  Similar support for other languages can be considered if requested for use in a serious project.</p>
  </section>
</chapter>
